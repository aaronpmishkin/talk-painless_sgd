@inproceedings{vaswani2019fast,
  title={Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron},
  author={Vaswani, Sharan and Bach, Francis and Schmidt, Mark},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1195--1204},
  year={2019}
}

@article{bassily2018exponential,
  title={On exponential convergence of sgd in non-convex over-parametrized learning},
  author={Bassily, Raef and Belkin, Mikhail and Ma, Siyuan},
  journal={arXiv preprint arXiv:1811.02564},
  year={2018}
}


@inproceedings{vaswanimlsgl19,
  author    = {Sharan Vaswani and
               Aaron Mishkin and
               Issam H. Laradji and
               Mark Schmidt and
               Gauthier Gidel and
               Simon Lacoste{-}Julien},
  title     = {Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence
               Rates},
  booktitle = {{NeurIPS}},
  pages     = {3727--3740},
  year      = {2019}
}

@inproceedings{nacson2018stochastic,
  author    = {Mor Shpigel Nacson and
               Nathan Srebro and
               Daniel Soudry},
  title     = {Stochastic Gradient Descent on Separable Data: Exact Convergence with
               a Fixed Learning Rate},
  booktitle = {{AISTATS}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {3051--3059},
  publisher = {{PMLR}},
  year      = {2019},
}

@inproceedings{wilson2017marginal,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={NeurIPS},
  pages={4148--4158},
  year={2017}
}

@inproceedings{liu2020accelerating,
  author    = {Chaoyue Liu and
               Mikhail Belkin},
  title     = {Accelerating {SGD} with momentum for over-parameterized learning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
}

@article{DBLP:journals/siamis/BeckT09,
  author    = {Amir Beck and
               Marc Teboulle},
  title     = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse
               Problems},
  journal   = {{SIAM} J. Imaging Sciences},
  volume    = {2},
  number    = {1},
  pages     = {183--202},
  year      = {2009},
}

% Workhorse of Machine Learning Papers: 16 so far...


@article{xu2017second,
  title={Second-order optimization for non-convex machine learning: An empirical study},
  author={Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07827},
  year={2017}
}

@article{zhang2016parallel,
  title={Parallel SGD: When does averaging help?},
  author={Zhang, Jian and De Sa, Christopher and Mitliagkas, Ioannis and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:1606.07365},
  year={2016}
}

@book{patterson2017deep,
  title={Deep learning: A practitioner's approach},
  author={Patterson, Josh and Gibson, Adam},
  year={2017},
  publisher={" O'Reilly Media, Inc."}
}

@inproceedings{pillaud2018statistical,
  title={Statistical optimality of stochastic gradient descent on hard learning problems through multiple passes},
  author={Pillaud-Vivien, Loucas and Rudi, Alessandro and Bach, Francis},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8114--8124},
  year={2018}
}

@inproceedings{grosse2015scaling,
  title={Scaling up natural gradient by sparsely factorizing the inverse fisher matrix},
  author={Grosse, Roger and Salakhudinov, Ruslan},
  booktitle={International Conference on Machine Learning},
  pages={2304--2313},
  year={2015}
}

@article{assran2018stochastic,
  title={Stochastic gradient push for distributed deep learning},
  author={Assran, Mahmoud and Loizou, Nicolas and Ballas, Nicolas and Rabbat, Michael},
  journal={arXiv preprint arXiv:1811.10792},
  year={2018}
}

@inproceedings{damaskinos2019aggregathor,
  title={Aggregathor: Byzantine machine learning via robust gradient aggregation},
  author={Damaskinos, Georgios and El Mhamdi, El Mahdi and Guerraoui, Rachid and Guirguis, Arsany Hany Abdelmessih and Rouault, S{\'e}bastien Louis Alexandre},
  booktitle={The Conference on Systems and Machine Learning (SysML), 2019},
  number={CONF},
  year={2019}
}

@inproceedings{kawaguchi2020ordered,
  author    = {Kenji Kawaguchi and
               Haihao Lu},
  _editor    = {Silvia Chiappa and
               Roberto Calandra},
  title     = {Ordered {SGD:} {A} New Stochastic Optimization Framework for Empirical
               Risk Minimization},
  booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2020},
  series    = {Proceedings of Machine Learning Research},
  volume    = {108},
  pages     = {669--679},
  publisher = {{PMLR}},
  year      = {2020},
}

@article{bernstein2018signsgd,
  title={signSGD with majority vote is communication efficient and fault tolerant},
  author={Bernstein, Jeremy and Zhao, Jiawei and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  journal={arXiv preprint arXiv:1810.05291},
  year={2018}
}

@inproceedings{li2019rsa,
  title={Rsa: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets},
  author={Li, Liping and Xu, Wei and Chen, Tianyi and Giannakis, Georgios B and Ling, Qing},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={1544--1551},
  year={2019}
}

@article{agarwal2017second,
  title={Second-order stochastic optimization for machine learning in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4148--4187},
  year={2017},
  publisher={JMLR. org}
}

@inproceedings{hofmann2015variance,
  title={Variance reduced stochastic gradient descent with neighbors},
  author={Hofmann, Thomas and Lucchi, Aurelien and Lacoste-Julien, Simon and McWilliams, Brian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2305--2313},
  year={2015}
}

@article{geffner2019rule,
  title={A Rule for Gradient Estimator Selection, with an Application to Variational Inference},
  author={Geffner, Tomas and Domke, Justin},
  journal={arXiv preprint arXiv:1911.01894},
  year={2019}
}

@article{assran2020convergence,
  title={On the Convergence of Nesterov's Accelerated Gradient Method in Stochastic Settings},
  author={Assran, Mahmoud and Rabbat, Michael},
  journal={arXiv preprint arXiv:2002.12414},
  year={2020}
}

@article{drori2019complexity,
  title={The complexity of finding stationary points with stochastic gradient descent},
  author={Drori, Yoel and Shamir, Ohad},
  journal={arXiv preprint arXiv:1910.01845},
  year={2019}
}

@article{gower2019sgd,
  title={SGD: General analysis and improved rates},
  author={Gower, Robert Mansel and Loizou, Nicolas and Qian, Xun and Sailanbayev, Alibek and Shulgin, Egor and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1901.09401},
  year={2019}
}
